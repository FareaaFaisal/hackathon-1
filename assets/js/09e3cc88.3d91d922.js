"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[480],{5889:(n,e,o)=>{o.r(e),o.d(e,{assets:()=>a,contentTitle:()=>c,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"robotic-nervous-system/05-humanoid-communication","title":"Humanoid Communication","description":"5.1 Overview","source":"@site/docs/01-robotic-nervous-system/05-humanoid-communication.md","sourceDirName":"01-robotic-nervous-system","slug":"/robotic-nervous-system/05-humanoid-communication","permalink":"/hackathon-1/docs/robotic-nervous-system/05-humanoid-communication","draft":false,"unlisted":false,"editUrl":"https://github.com/FareaaFaisal/hackathon-1/edit/main/docs/01-robotic-nervous-system/05-humanoid-communication.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"05-humanoid-communication","title":"Humanoid Communication","sidebar_label":"Humanoid Communication"},"sidebar":"tutorialSidebar","previous":{"title":"Building Packages","permalink":"/hackathon-1/docs/robotic-nervous-system/04-building-packages"},"next":{"title":"URDF Definition","permalink":"/hackathon-1/docs/robotic-nervous-system/06-urdf-definition"}}');var s=o(4848),t=o(8453);const r={id:"05-humanoid-communication",title:"Humanoid Communication",sidebar_label:"Humanoid Communication"},c="Chapter 5: Humanoid Communication",a={},l=[{value:"5.1 Overview",id:"51-overview",level:2},{value:"5.2 Joint State Communication",id:"52-joint-state-communication",level:2},{value:"5.3 Motion Planning",id:"53-motion-planning",level:2},{value:"5.4 Perception Communication",id:"54-perception-communication",level:2},{value:"5.5 Summary",id:"55-summary",level:2},{value:"5.6 Learning Outcomes",id:"56-learning-outcomes",level:2},{value:"References",id:"references",level:2}];function d(n){const e={a:"a",br:"br",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"chapter-5-humanoid-communication",children:"Chapter 5: Humanoid Communication"})}),"\n",(0,s.jsx)(e.h2,{id:"51-overview",children:"5.1 Overview"}),"\n",(0,s.jsxs)(e.p,{children:["Effective communication between a humanoid robot's components is crucial for coordinated behavior. In ROS 2, communication occurs through ",(0,s.jsx)(e.strong,{children:"Topics, Services, and Actions"}),", enabling different nodes to exchange information in real-time. This chapter explores the communication patterns necessary for humanoid tasks such as ",(0,s.jsx)(e.strong,{children:"walking, grasping, and perception"}),"."]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"52-joint-state-communication",children:"5.2 Joint State Communication"}),"\n",(0,s.jsxs)(e.p,{children:["The ",(0,s.jsx)(e.strong,{children:"joint state"})," represents the positions, velocities, and efforts of the robot's actuators. Publishing this information ensures that motion planners, state estimators, and visualization tools operate with accurate data."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Key Details"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Topic:"})," ",(0,s.jsx)(e.code,{children:"/joint_states"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Message Type:"})," ",(0,s.jsx)(e.code,{children:"sensor_msgs/msg/JointState"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Publisher:"})," Robot's motor controllers"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Subscribers:"})," State estimator, motion planner, and RViz"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Definition:"})," ",(0,s.jsx)(e.em,{children:"Joint State"}),": A ROS 2 message describing the current position, velocity, and effort of all robot joints."]}),"\n",(0,s.jsx)(e.p,{children:"This communication pattern allows components to monitor and respond to the robot's physical configuration in real-time."}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"53-motion-planning",children:"5.3 Motion Planning"}),"\n",(0,s.jsxs)(e.p,{children:["Motion planning involves generating ",(0,s.jsx)(e.strong,{children:"collision-free trajectories"})," for the robot\u2019s limbs. We use ",(0,s.jsx)(e.strong,{children:"MoveIt 2"}),", a ROS 2 motion planning framework, which provides services and actions for planning and executing movements."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Key Details"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Action:"})," ",(0,s.jsx)(e.code,{children:"/move_group"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Action Type:"})," ",(0,s.jsx)(e.code,{children:"moveit_msgs/action/MoveGroup"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Action Server:"})," MoveIt 2 ",(0,s.jsx)(e.code,{children:"move_group"})," node"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Action Client:"})," Any node requesting a motion plan"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Definition:"})," ",(0,s.jsx)(e.em,{children:"Motion Planning"}),": The computational process of determining a path from the robot's current state to a desired state while avoiding obstacles."]}),"\n",(0,s.jsx)(e.p,{children:"Through this communication pattern, humanoid robots can plan complex motions like walking, reaching, or grasping objects."}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"54-perception-communication",children:"5.4 Perception Communication"}),"\n",(0,s.jsxs)(e.p,{children:["The ",(0,s.jsx)(e.strong,{children:"perception system"})," processes sensor data to understand the environment. It integrates information from cameras, LiDAR, and other sensors to enable tasks like object detection, mapping, and human-robot interaction."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Key Details"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Topic:"})," ",(0,s.jsx)(e.code,{children:"/camera/image_raw"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Message Type:"})," ",(0,s.jsx)(e.code,{children:"sensor_msgs/msg/Image"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Publisher:"})," Robot\u2019s camera driver"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Subscribers:"})," Object detection node, visual SLAM node, human-robot interaction node"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Definition:"})," ",(0,s.jsx)(e.em,{children:"Perception"}),": The process of interpreting sensor data to build an understanding of the robot's environment."]}),"\n",(0,s.jsx)(e.p,{children:"This communication ensures that all components dependent on visual or depth information receive real-time updates for decision-making and control."}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"55-summary",children:"5.5 Summary"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["Humanoid robots rely on ROS 2 ",(0,s.jsx)(e.strong,{children:"Topics, Services, and Actions"})," for communication."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Joint state communication"})," provides actuator feedback to planners and visualization tools."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Motion planning actions"})," allow nodes to request collision-free trajectories using MoveIt 2."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Perception topics"})," distribute sensor information to multiple consumers for environment understanding."]}),"\n",(0,s.jsx)(e.li,{children:"These patterns form the foundation for coordinated humanoid behavior and complex task execution."}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"56-learning-outcomes",children:"5.6 Learning Outcomes"}),"\n",(0,s.jsx)(e.p,{children:"After completing this chapter, students will be able to:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Explain the role of Topics, Services, and Actions in humanoid robot communication."}),"\n",(0,s.jsx)(e.li,{children:"Describe how joint states are published and consumed by multiple components."}),"\n",(0,s.jsx)(e.li,{children:"Understand motion planning communication using MoveIt 2 actions."}),"\n",(0,s.jsx)(e.li,{children:"Identify perception topics and how sensor data is shared across nodes."}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,s.jsxs)(e.p,{children:["[1] S. Chitta et al., \u201cMoveIt 2: An Open Source Robotics Framework for Motion Planning,\u201d ",(0,s.jsx)(e.em,{children:"IEEE Robotics and Automation Letters"}),", vol. 3, no. 3, pp. 2200\u20132207, 2018.",(0,s.jsx)(e.br,{}),"\n","[2] ROS 2 Documentation, \u201cTopics, Services, and Actions,\u201d ",(0,s.jsx)(e.em,{children:(0,s.jsx)(e.a,{href:"https://docs.ros.org/en/humble/Concepts/About-Communication.html",children:"https://docs.ros.org/en/humble/Concepts/About-Communication.html"})}),".",(0,s.jsx)(e.br,{}),"\n","[3] Quigley, M., et al., \u201cROS: An Open-Source Robot Operating System,\u201d ",(0,s.jsx)(e.em,{children:"ICRA Workshop on Open Source Software"}),", 2009.",(0,s.jsx)(e.br,{}),"\n","[4] Siciliano, B., et al., ",(0,s.jsx)(e.em,{children:"Springer Handbook of Robotics"}),", 2nd ed., Springer, 2016."]})]})}function h(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},8453:(n,e,o)=>{o.d(e,{R:()=>r,x:()=>c});var i=o(6540);const s={},t=i.createContext(s);function r(n){const e=i.useContext(t);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function c(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:r(n.components),i.createElement(t.Provider,{value:e},n.children)}}}]);