"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[2419],{8311:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"vision-language-action/whisper-input","title":"Whisper for Speech Input","description":"Whisper for Speech Input","source":"@site/docs/04-vision-language-action/02-whisper-input.md","sourceDirName":"04-vision-language-action","slug":"/vision-language-action/whisper-input","permalink":"/hackathon-1/docs/vision-language-action/whisper-input","draft":false,"unlisted":false,"editUrl":"https://github.com/FareaaFaisal/hackathon-1/edit/main/docs/04-vision-language-action/02-whisper-input.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Whisper for Speech Input"},"sidebar":"tutorialSidebar","previous":{"title":"Introduction to VLA Robotics","permalink":"/hackathon-1/docs/vision-language-action/vla-intro"},"next":{"title":"LLM Planning","permalink":"/hackathon-1/docs/vision-language-action/llm-planning"}}');var s=i(4848),o=i(8453);const r={sidebar_position:2,title:"Whisper for Speech Input"},a=void 0,c={},l=[{value:"Whisper for Speech Input",id:"whisper-for-speech-input",level:2},{value:"Requirements:",id:"requirements",level:3},{value:"Success Criteria:",id:"success-criteria",level:3}];function p(e){const n={h2:"h2",h3:"h3",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"whisper-for-speech-input",children:"Whisper for Speech Input"}),"\n",(0,s.jsx)(n.p,{children:"This chapter covers installing and capturing commands using OpenAI's Whisper model for speech input."}),"\n",(0,s.jsx)(n.h3,{id:"requirements",children:"Requirements:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Install Whisper."}),"\n",(0,s.jsx)(n.li,{children:"Capture commands."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"success-criteria",children:"Success Criteria:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Voice \u2192 text pipeline working."}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Learning Outcomes"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Integrate OpenAI's Whisper model for robust speech-to-text conversion."}),"\n",(0,s.jsx)(n.li,{children:"Implement methods to capture and process voice commands for robotic systems."}),"\n",(0,s.jsx)(n.li,{children:"Validate a functional voice-to-text pipeline for natural language interaction."}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(6540);const s={},o=t.createContext(s);function r(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);