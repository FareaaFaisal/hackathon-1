"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[2971],{5558:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"digital-twin/hri-sim","title":"Human-Robot Interaction Sim","description":"Chapter 7:","source":"@site/docs/02-digital-twin/07-hri-sim.md","sourceDirName":"02-digital-twin","slug":"/digital-twin/hri-sim","permalink":"/hackathon-1/docs/digital-twin/hri-sim","draft":false,"unlisted":false,"editUrl":"https://github.com/FareaaFaisal/hackathon-1/edit/main/docs/02-digital-twin/07-hri-sim.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7,"title":"Human-Robot Interaction Sim"},"sidebar":"tutorialSidebar","previous":{"title":"Unity Integration","permalink":"/hackathon-1/docs/digital-twin/unity-integration"},"next":{"title":"Build a Complete Digital Twin","permalink":"/hackathon-1/docs/digital-twin/complete-digital-twin"}}');var s=i(4848),o=i(8453);const r={sidebar_position:7,title:"Human-Robot Interaction Sim"},a=void 0,l={},c=[{value:"Chapter 7:",id:"chapter-7",level:2},{value:"7.1 Importance of HRI Simulation",id:"71-importance-of-hri-simulation",level:2},{value:"7.2 Simulating Human Avatars",id:"72-simulating-human-avatars",level:2},{value:"Step-by-Step Avatar Integration:",id:"step-by-step-avatar-integration",level:3},{value:"7.3 Gesture Recognition Simulation",id:"73-gesture-recognition-simulation",level:2},{value:"7.4 Obstacle Simulation",id:"74-obstacle-simulation",level:2},{value:"7.5 Integrating HRI with ROS 2",id:"75-integrating-hri-with-ros-2",level:2},{value:"7.6 Validation of HRI",id:"76-validation-of-hri",level:2},{value:"7.7 Summary",id:"77-summary",level:2},{value:"7.8 Learning Outcomes",id:"78-learning-outcomes",level:2},{value:"References",id:"references",level:2}];function d(n){const e={a:"a",blockquote:"blockquote",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.h2,{id:"chapter-7",children:"Chapter 7:"}),"\n",(0,s.jsxs)(e.p,{children:["Simulating ",(0,s.jsx)(e.strong,{children:"human-robot interaction (HRI)"})," is crucial for validating humanoid robots in environments where they coexist with humans. Accurate simulation allows testing of ",(0,s.jsx)(e.strong,{children:"gesture recognition, obstacle avoidance, and social navigation"})," before deployment in real-world scenarios."]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"71-importance-of-hri-simulation",children:"7.1 Importance of HRI Simulation"}),"\n",(0,s.jsx)(e.p,{children:"Human-robot interaction simulations enable:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Safety validation:"})," Ensuring the robot does not collide with humans."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Behavior testing:"})," Observing robot responses to gestures and commands."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Training perception models:"})," Using simulated humans to train vision and gesture recognition algorithms."]}),"\n"]}),"\n",(0,s.jsxs)(e.blockquote,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Definition:"})," ",(0,s.jsx)(e.em,{children:"HRI Simulation"}),": The use of virtual environments to model and test interactions between humans and robots under controlled conditions."]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"72-simulating-human-avatars",children:"7.2 Simulating Human Avatars"}),"\n",(0,s.jsxs)(e.p,{children:["Human avatars are represented as ",(0,s.jsx)(e.strong,{children:"kinematic models"})," or ",(0,s.jsx)(e.strong,{children:"skeletal meshes"})," with defined joints and animations."]}),"\n",(0,s.jsx)(e.h3,{id:"step-by-step-avatar-integration",children:"Step-by-Step Avatar Integration:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Import a human model"})," (FBX, GLTF) into the simulation engine (Unity or Gazebo)."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Define skeletal joints"})," for gesture recognition and motion tracking."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Add colliders and rigid bodies"})," to prevent interpenetration with the robot."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Animate gestures"})," using predefined animations or procedural motion scripts."]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Example (Unity C# script for arm waving):"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",children:'Animator animator = humanAvatar.GetComponent<Animator>();\r\nanimator.Play("Wave");\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Ensures the robot can detect gestures using vision sensors or simulated LiDAR."}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"73-gesture-recognition-simulation",children:"7.3 Gesture Recognition Simulation"}),"\n",(0,s.jsx)(e.p,{children:"Gestures are essential for natural HRI. Common gestures include pointing, waving, or signaling stop/go."}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Use simulated RGB-D cameras or skeleton tracking to capture gestures."}),"\n",(0,s.jsx)(e.li,{children:"Map gestures to robot behaviors via ROS 2 topics:"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",children:'// Publish gesture intent to ROS 2\r\nGestureMsg gesture = new GestureMsg();\r\ngesture.type = "wave";\r\nros.Publish("/human_gesture", gesture);\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:'Robot subscribers interpret these gestures to adjust behavior, e.g., stopping movement when a "stop" gesture is detected.'}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"74-obstacle-simulation",children:"7.4 Obstacle Simulation"}),"\n",(0,s.jsx)(e.p,{children:"In human-populated environments, obstacles are dynamic. Simulate:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Moving humans: walking along predefined paths or random trajectories."}),"\n",(0,s.jsx)(e.li,{children:"Static obstacles: furniture, walls, or props."}),"\n",(0,s.jsx)(e.li,{children:"Interactive objects: doors, tools, or objects that humans move."}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Use collision meshes and physics engines to test robot navigation and safety algorithms:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<collision>\r\n  <geometry>\r\n    <box size="0.5 0.5 1.8"/>\r\n  </geometry>\r\n</collision>\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Robots should dynamically avoid collisions while completing tasks."}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"75-integrating-hri-with-ros-2",children:"7.5 Integrating HRI with ROS 2"}),"\n",(0,s.jsx)(e.p,{children:"ROS 2 nodes enable real-time HRI simulation:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Publish human pose and gesture:"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"from geometry_msgs.msg import Pose\r\nfrom sensor_msgs.msg import JointState\r\nimport rclpy\r\n\r\n# Node publishes simulated human joint states\n"})}),"\n",(0,s.jsxs)(e.ol,{start:"2",children:["\n",(0,s.jsx)(e.li,{children:"Subscribe robot to human topics: Robot uses the data to plan motion or respond to gestures."}),"\n",(0,s.jsx)(e.li,{children:"Test safety rules: Ensure the robot maintains safe distance and adapts speed in real time."}),"\n"]}),"\n",(0,s.jsxs)(e.blockquote,{children:["\n",(0,s.jsx)(e.p,{children:"Tip: Use Gazebo or Unity physics engines to simulate dynamic interactions, ensuring accurate collision response."}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"76-validation-of-hri",children:"7.6 Validation of HRI"}),"\n",(0,s.jsx)(e.p,{children:"To validate human-robot interactions:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Collision tests: Robot should stop or reroute to prevent collisions."}),"\n",(0,s.jsx)(e.li,{children:"Gesture response tests: Verify robot responds correctly to waving, pointing, or other human cues."}),"\n",(0,s.jsx)(e.li,{children:"Proximity checks: Robot maintains minimum safety distance from humans."}),"\n",(0,s.jsx)(e.li,{children:"Scenario testing: Combine multiple humans and obstacles in the environment to test navigation, perception, and task execution."}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"77-summary",children:"7.7 Summary"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"HRI simulation allows testing humanoid robots safely in human-centric environments."}),"\n",(0,s.jsx)(e.li,{children:"Simulating human avatars, gestures, and obstacles ensures robots behave predictably and safely."}),"\n",(0,s.jsx)(e.li,{children:"ROS 2 integration enables real-time interaction between simulated humans and robots."}),"\n",(0,s.jsx)(e.li,{children:"Validation ensures the robot can operate effectively in crowded or dynamic scenarios."}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"78-learning-outcomes",children:"7.8 Learning Outcomes"}),"\n",(0,s.jsx)(e.p,{children:"After completing this chapter, students will be able to:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Configure simulations with human avatars and integrate them with robots."}),"\n",(0,s.jsx)(e.li,{children:"Simulate and recognize human gestures to influence robot behavior."}),"\n",(0,s.jsx)(e.li,{children:"Create dynamic obstacles and validate robot navigation in human-populated environments."}),"\n",(0,s.jsx)(e.li,{children:"Integrate human simulation with ROS 2 topics for real-time interaction."}),"\n",(0,s.jsx)(e.li,{children:"Evaluate the safety and effectiveness of humanoid robots in human-centric scenarios."}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,s.jsx)(e.p,{children:"[1] Goodrich, M. A., Schultz, A. C., \u201cHuman-Robot Interaction: A Survey,\u201d Foundations and Trends in Human-Computer Interaction, 2007."}),"\n",(0,s.jsxs)(e.p,{children:["[2] Unity Technologies, \u201cHuman Avatars and Animation,\u201d ",(0,s.jsx)(e.a,{href:"https://docs.unity3d.com/Manual/AnimationOverview.html",children:"https://docs.unity3d.com/Manual/AnimationOverview.html"})]}),"\n",(0,s.jsxs)(e.p,{children:["[3] ROS 2 Documentation, \u201cInterfacing with Human Simulation,\u201d ",(0,s.jsx)(e.a,{href:"https://docs.ros.org",children:"https://docs.ros.org"})]}),"\n",(0,s.jsx)(e.p,{children:"[4] Siciliano, B., et al., Springer Handbook of Robotics, 2nd ed., Springer, 2016."}),"\n",(0,s.jsx)(e.p,{children:"[5] Koenig, N., Howard, A., \u201cGazebo Simulation for Human-Robot Interaction,\u201d IEEE/RSJ IROS, 2004."}),"\n",(0,s.jsx)(e.hr,{})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>a});var t=i(6540);const s={},o=t.createContext(s);function r(n){const e=t.useContext(o);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:r(n.components),t.createElement(o.Provider,{value:e},n.children)}}}]);