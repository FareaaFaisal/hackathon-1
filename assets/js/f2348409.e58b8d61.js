"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[1391],{8453:(n,i,e)=>{e.d(i,{R:()=>r,x:()=>l});var t=e(6540);const o={},s=t.createContext(o);function r(n){const i=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(i):{...i,...n}},[i,n])}function l(n){let i;return i=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:r(n.components),t.createElement(s.Provider,{value:i},n.children)}},9160:(n,i,e)=>{e.r(i),e.d(i,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"digital-twin/complete-digital-twin","title":"Build a Complete Digital Twin","description":"Chapter 8:","source":"@site/docs/02-digital-twin/08-complete-digital-twin.md","sourceDirName":"02-digital-twin","slug":"/digital-twin/complete-digital-twin","permalink":"/hackathon-1/docs/digital-twin/complete-digital-twin","draft":false,"unlisted":false,"editUrl":"https://github.com/FareaaFaisal/hackathon-1/edit/main/docs/02-digital-twin/08-complete-digital-twin.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"title":"Build a Complete Digital Twin"},"sidebar":"tutorialSidebar","previous":{"title":"Human-Robot Interaction Sim","permalink":"/hackathon-1/docs/digital-twin/hri-sim"},"next":{"title":"Overview of NVIDIA Isaac Ecosystem","permalink":"/hackathon-1/docs/ai-robot-brain/isaac-ecosystem"}}');var o=e(4848),s=e(8453);const r={sidebar_position:8,title:"Build a Complete Digital Twin"},l=void 0,a={},c=[{value:"Chapter 8:",id:"chapter-8",level:2},{value:"8.1 Components of a Digital Twin",id:"81-components-of-a-digital-twin",level:2},{value:"8.2 Importing the Robot Model",id:"82-importing-the-robot-model",level:2},{value:"8.3 Integrating Sensors",id:"83-integrating-sensors",level:2},{value:"8.4 Environment Setup",id:"84-environment-setup",level:2},{value:"8.5 Controllers and Motion Integration",id:"85-controllers-and-motion-integration",level:2},{value:"8.6 Combining All Components",id:"86-combining-all-components",level:2},{value:"8.7 Validation and Optimization",id:"87-validation-and-optimization",level:2},{value:"8.8 Summary",id:"88-summary",level:2},{value:"8.9 Learning Outcomes",id:"89-learning-outcomes",level:2},{value:"References",id:"references",level:2}];function d(n){const i={a:"a",blockquote:"blockquote",code:"code",em:"em",h2:"h2",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(i.h2,{id:"chapter-8",children:"Chapter 8:"}),"\n",(0,o.jsxs)(i.p,{children:["A ",(0,o.jsx)(i.strong,{children:"digital twin"})," is a virtual replica of a physical robot that mirrors its structure, sensors, and behavior in a simulated environment. Combining robot models, sensors, and environments allows researchers and engineers to ",(0,o.jsx)(i.strong,{children:"test, validate, and optimize humanoid robots"})," before deploying them in the real world."]}),"\n",(0,o.jsxs)(i.p,{children:["This chapter demonstrates how to integrate all components of a humanoid robot into a ",(0,o.jsx)(i.strong,{children:"full digital twin"})," using Unity, Gazebo, and ROS 2."]}),"\n",(0,o.jsx)(i.hr,{}),"\n",(0,o.jsx)(i.h2,{id:"81-components-of-a-digital-twin",children:"8.1 Components of a Digital Twin"}),"\n",(0,o.jsx)(i.p,{children:"A complete digital twin integrates:"}),"\n",(0,o.jsxs)(i.ol,{children:["\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Robot Model:"})," The URDF or SDF representation of the humanoid with correct links, joints, and kinematics."]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Sensors:"})," LiDAR, RGB cameras, Depth cameras, IMU, and tactile sensors."]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Environment:"})," Static and dynamic objects, obstacles, and human avatars."]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Controllers and ROS 2 Nodes:"})," Responsible for motion, perception, and interaction."]}),"\n"]}),"\n",(0,o.jsxs)(i.blockquote,{children:["\n",(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.strong,{children:"Definition:"})," ",(0,o.jsx)(i.em,{children:"Digital Twin"}),": A high-fidelity virtual representation of a physical system that provides real-time simulation, monitoring, and analysis."]}),"\n"]}),"\n",(0,o.jsx)(i.hr,{}),"\n",(0,o.jsx)(i.h2,{id:"82-importing-the-robot-model",children:"8.2 Importing the Robot Model"}),"\n",(0,o.jsxs)(i.ol,{children:["\n",(0,o.jsxs)(i.li,{children:["Export the humanoid robot model to ",(0,o.jsx)(i.strong,{children:"FBX"})," or ",(0,o.jsx)(i.strong,{children:"GLTF"})," for Unity, or use the URDF/SDF directly in Gazebo."]}),"\n",(0,o.jsxs)(i.li,{children:["Ensure ",(0,o.jsx)(i.strong,{children:"joint orientations, scales, and link hierarchies"})," match the original robot."]}),"\n",(0,o.jsxs)(i.li,{children:["Import the model into the simulation engine and verify ",(0,o.jsx)(i.strong,{children:"colliders, rigid bodies, and physical properties"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(i.blockquote,{children:["\n",(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.strong,{children:"Tip:"})," Align the robot\u2019s reference frame with the simulation world to avoid discrepancies in motion or perception."]}),"\n"]}),"\n",(0,o.jsx)(i.hr,{}),"\n",(0,o.jsx)(i.h2,{id:"83-integrating-sensors",children:"8.3 Integrating Sensors"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"LiDAR:"})," Configure the sensor in URDF/SDF or as a Unity sensor plugin."]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"RGB/Depth Cameras:"})," Attach cameras to the robot links with appropriate FOV and resolution."]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"IMU:"})," Add IMU sensors to the robot base or torso for state estimation."]}),"\n"]}),"\n",(0,o.jsx)(i.p,{children:"ROS 2 publishers should be configured for each sensor topic:"}),"\n",(0,o.jsx)(i.pre,{children:(0,o.jsx)(i.code,{className:"language-python",children:"# Example: ROS 2 publisher for LiDAR data\r\nfrom sensor_msgs.msg import LaserScan\r\nimport rclpy\r\n\r\n# Node publishes simulated LiDAR data\n"})}),"\n",(0,o.jsxs)(i.blockquote,{children:["\n",(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.strong,{children:"Tip:"})," Simulate sensor noise and delay to approximate real-world conditions."]}),"\n"]}),"\n",(0,o.jsx)(i.hr,{}),"\n",(0,o.jsx)(i.h2,{id:"84-environment-setup",children:"8.4 Environment Setup"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Static Environment:"})," Floors, walls, furniture, and props."]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Dynamic Environment:"})," Moving obstacles, human avatars, and interactive objects."]}),"\n",(0,o.jsxs)(i.li,{children:["Ensure ",(0,o.jsx)(i.strong,{children:"physics colliders and rigid bodies"})," are configured for accurate interaction."]}),"\n"]}),"\n",(0,o.jsxs)(i.blockquote,{children:["\n",(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.strong,{children:"Tip:"})," Use Prefabs in Unity or reusable models in Gazebo to maintain consistency across simulations."]}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"85-controllers-and-motion-integration",children:"8.5 Controllers and Motion Integration"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Implement joint controllers using ROS 2 control packages."}),"\n",(0,o.jsx)(i.li,{children:"Configure trajectory execution for walking, grasping, and manipulation."}),"\n",(0,o.jsx)(i.li,{children:"Test real-time interaction with sensors and environment objects."}),"\n"]}),"\n",(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.strong,{children:"Example:"})," ROS 2 control subscriber:"]}),"\n",(0,o.jsx)(i.pre,{children:(0,o.jsx)(i.code,{className:"language-python",children:"from control_msgs.msg import JointTrajectoryControllerState\r\nimport rclpy\r\n\r\n# Node subscribes to joint states for motion planning\n"})}),"\n",(0,o.jsx)(i.hr,{}),"\n",(0,o.jsx)(i.h2,{id:"86-combining-all-components",children:"8.6 Combining All Components"}),"\n",(0,o.jsx)(i.p,{children:"Steps to build the complete digital twin:"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Import the humanoid model into the simulation engine."}),"\n",(0,o.jsx)(i.li,{children:"Attach sensors and configure ROS 2 topics for publishing sensor data."}),"\n",(0,o.jsx)(i.li,{children:"Load the environment with static and dynamic elements."}),"\n",(0,o.jsx)(i.li,{children:"Configure controllers to execute motion and respond to sensor input."}),"\n",(0,o.jsx)(i.li,{children:"Test integrated behaviors, including perception, motion, and interaction."}),"\n"]}),"\n",(0,o.jsxs)(i.blockquote,{children:["\n",(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.strong,{children:"Tip:"})," Start with a simple scenario and gradually increase complexity for debugging and validation."]}),"\n"]}),"\n",(0,o.jsx)(i.hr,{}),"\n",(0,o.jsx)(i.h2,{id:"87-validation-and-optimization",children:"8.7 Validation and Optimization"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Performance Metrics: Ensure simulation runs in real-time or near real-time."}),"\n",(0,o.jsx)(i.li,{children:"Accuracy Checks: Verify sensors, joint movements, and environment interactions match expected behavior."}),"\n",(0,o.jsx)(i.li,{children:"Optimization: Reduce unnecessary physics calculations or sensor sampling rates if performance drops."}),"\n"]}),"\n",(0,o.jsx)(i.p,{children:(0,o.jsx)(i.strong,{children:"Example Test Cases:"})}),"\n",(0,o.jsxs)(i.ol,{children:["\n",(0,o.jsx)(i.li,{children:"Robot navigates through a room with static obstacles."}),"\n",(0,o.jsx)(i.li,{children:"Robot reacts to gestures from simulated humans."}),"\n",(0,o.jsx)(i.li,{children:"Sensor data feeds into perception and motion planning nodes accurately."}),"\n"]}),"\n",(0,o.jsx)(i.hr,{}),"\n",(0,o.jsx)(i.h2,{id:"88-summary",children:"8.8 Summary"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"A complete digital twin integrates the robot model, sensors, environment, and controllers."}),"\n",(0,o.jsx)(i.li,{children:"Enables safe testing and validation of humanoid robots before real-world deployment."}),"\n",(0,o.jsx)(i.li,{children:"ROS 2 integration allows real-time simulation, sensor feedback, and control."}),"\n",(0,o.jsx)(i.li,{children:"Iterative testing and optimization ensure accuracy and performance."}),"\n"]}),"\n",(0,o.jsx)(i.hr,{}),"\n",(0,o.jsx)(i.h2,{id:"89-learning-outcomes",children:"8.9 Learning Outcomes"}),"\n",(0,o.jsx)(i.p,{children:"After completing this chapter, students will be able to:"}),"\n",(0,o.jsxs)(i.ol,{children:["\n",(0,o.jsx)(i.li,{children:"Integrate all components of a digital twin: robot model, sensors, and environment."}),"\n",(0,o.jsx)(i.li,{children:"Configure controllers and ROS 2 nodes for realistic robot behavior."}),"\n",(0,o.jsx)(i.li,{children:"Validate motion, perception, and interaction in a fully simulated environment."}),"\n",(0,o.jsx)(i.li,{children:"Troubleshoot and optimize the complete digital twin for performance and fidelity."}),"\n",(0,o.jsx)(i.li,{children:"Demonstrate a fully functional humanoid robot digital twin in simulation."}),"\n"]}),"\n",(0,o.jsx)(i.hr,{}),"\n",(0,o.jsx)(i.h2,{id:"references",children:"References"}),"\n",(0,o.jsxs)(i.p,{children:["[1] Unity Technologies, \u201cUnity Robotics Hub,\u201d ",(0,o.jsx)(i.a,{href:"https://github.com/Unity-Technologies/Unity-Robotics-Hub",children:"https://github.com/Unity-Technologies/Unity-Robotics-Hub"})]}),"\n",(0,o.jsxs)(i.p,{children:["[2] ROS 2 Documentation, \u201cSimulation and Digital Twin Integration,\u201d ",(0,o.jsx)(i.a,{href:"https://docs.ros.org",children:"https://docs.ros.org"})]}),"\n",(0,o.jsx)(i.p,{children:"[3] Siciliano, B., et al., Springer Handbook of Robotics, 2nd ed., Springer, 2016."}),"\n",(0,o.jsx)(i.p,{children:"[4] Goodrich, M. A., Schultz, A. C., \u201cHuman-Robot Interaction: A Survey,\u201d Foundations and Trends in Human-Computer Interaction, 2007."}),"\n",(0,o.jsx)(i.p,{children:"[5] Koenig, N., Howard, A., \u201cGazebo Simulation for Digital Twins,\u201d IEEE/RSJ IROS, 2004."}),"\n",(0,o.jsx)(i.hr,{})]})}function h(n={}){const{wrapper:i}={...(0,s.R)(),...n.components};return i?(0,o.jsx)(i,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}}}]);