"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[3087],{657:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>r,contentTitle:()=>l,default:()=>d,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"vision-language-action/llm-planning","title":"LLM Planning","description":"LLM Planning","source":"@site/docs/04-vision-language-action/03-llm-planning.md","sourceDirName":"04-vision-language-action","slug":"/vision-language-action/llm-planning","permalink":"/hackathon-1/docs/vision-language-action/llm-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/FareaaFaisal/hackathon-1/edit/main/docs/04-vision-language-action/03-llm-planning.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"LLM Planning"},"sidebar":"tutorialSidebar","previous":{"title":"Whisper for Speech Input","permalink":"/hackathon-1/docs/vision-language-action/whisper-input"},"next":{"title":"Vision-Language Models","permalink":"/hackathon-1/docs/vision-language-action/vlm"}}');var a=i(4848),s=i(8453);const o={sidebar_position:3,title:"LLM Planning"},l=void 0,r={},c=[{value:"LLM Planning",id:"llm-planning",level:2},{value:"Requirements:",id:"requirements",level:3},{value:"Success Criteria:",id:"success-criteria",level:3}];function u(n){const e={h2:"h2",h3:"h3",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.h2,{id:"llm-planning",children:"LLM Planning"}),"\n",(0,a.jsx)(e.p,{children:"This chapter focuses on converting natural language tasks into ROS 2 actions using Large Language Models (LLMs)."}),"\n",(0,a.jsx)(e.h3,{id:"requirements",children:"Requirements:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Convert natural language tasks into ROS 2 actions."}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"success-criteria",children:"Success Criteria:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"LLM produces step-by-step humanoid plans."}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Learning Outcomes"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Understand how Large Language Models (LLMs) can be integrated into robotic planning."}),"\n",(0,a.jsx)(e.li,{children:"Implement methods to translate natural language commands into a sequence of ROS 2 actions."}),"\n",(0,a.jsx)(e.li,{children:"Develop LLM-based planners that generate robust, step-by-step plans for humanoid robots."}),"\n"]})]})}function d(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(u,{...n})}):u(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>l});var t=i(6540);const a={},s=t.createContext(a);function o(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);