"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[7615],{7198:(i,e,n)=>{n.r(e),n.d(e,{assets:()=>r,contentTitle:()=>l,default:()=>d,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"vision-language-action/multimodal-pipeline","title":"Multimodal Pipeline","description":"Multimodal Pipeline","source":"@site/docs/04-vision-language-action/05-multimodal-pipeline.md","sourceDirName":"04-vision-language-action","slug":"/vision-language-action/multimodal-pipeline","permalink":"/hackathon-1/docs/vision-language-action/multimodal-pipeline","draft":false,"unlisted":false,"editUrl":"https://github.com/FareaaFaisal/hackathon-1/edit/main/docs/04-vision-language-action/05-multimodal-pipeline.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Multimodal Pipeline"},"sidebar":"tutorialSidebar","previous":{"title":"Vision-Language Models","permalink":"/hackathon-1/docs/vision-language-action/vlm"},"next":{"title":"LLM \u2192 ROS Action Execution","permalink":"/hackathon-1/docs/vision-language-action/llm-to-ros"}}');var o=n(4848),a=n(8453);const s={sidebar_position:5,title:"Multimodal Pipeline"},l=void 0,r={},c=[{value:"Multimodal Pipeline",id:"multimodal-pipeline",level:2},{value:"Requirements:",id:"requirements",level:3},{value:"Success Criteria:",id:"success-criteria",level:3}];function u(i){const e={h2:"h2",h3:"h3",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...i.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.h2,{id:"multimodal-pipeline",children:"Multimodal Pipeline"}),"\n",(0,o.jsx)(e.p,{children:"This chapter focuses on combining voice, vision, navigation, and manipulation into a unified ROS 2 + LLM system."}),"\n",(0,o.jsx)(e.h3,{id:"requirements",children:"Requirements:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Combine voice, vision, navigation, manipulation."}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"success-criteria",children:"Success Criteria:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Unified ROS 2 + LLM system."}),"\n"]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Learning Outcomes"}),":"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Integrate diverse modalities (voice, vision, navigation, manipulation) into a coherent robotic system."}),"\n",(0,o.jsx)(e.li,{children:"Develop a unified ROS 2 and LLM-based architecture for multimodal control."}),"\n",(0,o.jsx)(e.li,{children:"Achieve seamless interaction between different sensory inputs and action outputs in a humanoid robot."}),"\n"]})]})}function d(i={}){const{wrapper:e}={...(0,a.R)(),...i.components};return e?(0,o.jsx)(e,{...i,children:(0,o.jsx)(u,{...i})}):u(i)}},8453:(i,e,n)=>{n.d(e,{R:()=>s,x:()=>l});var t=n(6540);const o={},a=t.createContext(o);function s(i){const e=t.useContext(a);return t.useMemo(function(){return"function"==typeof i?i(e):{...e,...i}},[e,i])}function l(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(o):i.components||o:s(i.components),t.createElement(a.Provider,{value:e},i.children)}}}]);